name: News Ingestion Scheduler

on:
  schedule:
    # Run every 2 hours (at :00 minutes)
    - cron: '0 */2 * * *'
  # Allow manual triggering for testing
  workflow_dispatch:

jobs:
  trigger-ingestion:
    # Only run on the main branch to prevent accidental production changes
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    
    steps:
    - name: Trigger News Ingestion
      run: |
        set -e
        set -o pipefail

        echo "üîÑ Triggering news ingestion at $(date)"

        if [ -z "${{ secrets.VERCEL_URL }}" ]; then
          echo "‚ùå Error: VERCEL_URL secret is not set."
          exit 1
        fi

        if [ -z "${{ secrets.CRON_SECRET }}" ]; then
          echo "‚ùå Error: CRON_SECRET secret is not set."
          exit 1
        fi
        
        # Call our Next.js API endpoint which will trigger the Supabase function
        # Increase timeout to 10 minutes for batch processing
        response=$(curl --max-time 600 --fail -s -w "\n%{http_code}" -X POST \
          "${{ secrets.VERCEL_URL }}/api/trigger-ingestion" \
          -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}" \
          -H "Content-Type: application/json")
        
        # Extract HTTP status code
        http_code=$(echo "$response" | tail -n1)
        body=$(echo "$response" | head -n -1)
        
        echo "üåê Calling: ${{ secrets.VERCEL_URL }}/api/trigger-ingestion"
        echo "HTTP Status: $http_code"
        
        # Check if request was successful
        if [ "$http_code" -ge 200 ] && [ "$http_code" -lt 300 ]; then
          echo "‚úÖ News ingestion completed successfully"
          
          # Parse and display batch processing results
          if command -v jq &> /dev/null && [ -n "$body" ]; then
            echo "üìä Ingestion Summary:"
            
            # Extract key metrics
            total_processed=$(echo "$body" | jq -r '.summary.total_processed // 0')
            total_inserted=$(echo "$body" | jq -r '.summary.total_inserted // 0')
            batches_executed=$(echo "$body" | jq -r '.summary.batches_executed // 0')
            execution_time=$(echo "$body" | jq -r '.summary.execution_time_seconds // 0')
            
            echo "  üì∞ Articles processed: $total_processed"
            echo "  ‚ûï New articles added: $total_inserted"
            echo "  üì¶ Batches executed: $batches_executed"
            echo "  ‚è±Ô∏è  Execution time: ${execution_time}s"
            
            # Check for errors
            errors=$(echo "$body" | jq -r '.errors // empty | length')
            if [ "$errors" -gt 0 ] 2>/dev/null; then
              echo "‚ö†Ô∏è  Warnings/Errors encountered:"
              echo "$body" | jq -r '.errors[]' | head -10 | sed 's/^/    /'
              if [ "$errors" -gt 10 ]; then
                echo "    ... and $((errors - 10)) more errors (check logs for details)"
              fi
            fi
            
            # Show full response in debug mode
            echo "üìÑ Full Response:"
            echo "$body" | jq '.' || echo "$body"
          else
            echo "Response: $body"
          fi
        else
          echo "‚ùå News ingestion failed with status: $http_code"
          echo "Response body: $body"
          
          # Try to extract error details if JSON
          if command -v jq &> /dev/null && [ -n "$body" ]; then
            error_details=$(echo "$body" | jq -r '.details // .error // empty')
            if [ -n "$error_details" ]; then
              echo "Error details: $error_details"
            fi
          fi
          
          exit 1
        fi

    - name: Log Completion
      run: |
        echo "üì∞ News ingestion workflow completed at $(date)"
        echo "‚è∞ Next scheduled run will be in 2 hours"
